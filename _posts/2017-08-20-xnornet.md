---
title: "深度学习模型压缩之二值网络"
layout: post
date: 2017-08-20
tag: mxnet
blog: true
star: true
author: karl
category: mxnet
description: 自定义Op
---

## 前言  

因为实习的原因好久没有写博客，今天把实习期间做的东西总结一下，也算给两个月的学习有个交代。模型压缩的目的是为了将模型压缩至可以接受
的大小。目前来说一种做法利用剪枝，挑选有用的权重，剔除冗余的权重链接，进而达到模型压缩的目的；另外一种便是基于模型训练的方法，
将模型权重量化至8bit， 4bit甚至1bit。使得模型由原来的float或者double转为1bit的模型，这样理论上可以压缩至32x, 速度方面可以利用bit运算
达到加速网络的效果。  

## 