---
title: "深度学习模型压缩之二值网络"
layout: post
date: 2017-08-20
tag: mxnet
blog: true
star: true
author: karl
category: paper
description: 自定义Op
---

## 前言  

因为实习的原因好久没有写博客，今天把实习期间做的东西总结一下，也算给两个月的学习有个交代。模型压缩的目的是为了将模型压缩至可以接受
的大小。目前来说一种做法利用剪枝，挑选有用的权重，剔除冗余的权重链接，进而达到模型压缩的目的；另外一种便是基于模型训练的方法，
将模型权重量化至8bit， 4bit甚至1bit。使得模型由原来的float或者double转为1bit的模型，这样理论上可以压缩至32x, 速度方面可以利用bit运算
达到加速网络的效果，但会带来精度上的损失。今天就主要总结一下这部分的东西。  

## XNOR-NET  

BNN主要说一下XNOR-NET,因为它里面包含了权重的二值化，输出的二值化。  

### 权重二值化  
权重二值化怎么做呢，假设我们二值化后的权重为$$B$$,全精度的权重为$$W$$, 那么两者应该满足一下关系:  

$$
\begin{equation}
\min \ ||W\ -\ \alpha B||
\end{equation}
$$

