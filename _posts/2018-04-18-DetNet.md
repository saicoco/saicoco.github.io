---
title: DetNet,A Backbone network for object detection
layout: post
date: 2018-04-18
categories: 
- paper_reading
tag: paper
blog: true
start: true
author: karl
description: 目标检测
header:
   image_fullwidth: "paper.jpg"
---  

DetNet是face++ ECCV2018的文章，文章主要针对目标检测现有backbone的不足进行分析并作出了相应的改进，最终在mscoco上得到了state-of-the-art的结果。  

## idea  
文章认为，现有的目标检测方法使用的backbone多为分类模型，即都是imagenet的pretrained model，作者认为分类和检测之间存在较大的gap：分类目的在于获取全局的上下文信息，通过一系列的pooling增加stride，进而在网络深层获取较强的语义信息，用于分类。对于检测，则包含两个任务,分类和定位。分类需要全局语义信息，定位则需要较为精细的feature map。上述可以看出，基于imagenet的分类model虽然具备较强的语义信息，但是目的是分类，必然会导致较多像素信息的损失，因此提出了基于dilated conv的基本block，在高分辨率的feature map上，保证像素信息不丢失的情况下，提升模型感受野。  

具体来说，对于较大的目标，通常可以利用较为深层的特征图进行定位和识别，但是传统基于分类的backbone通过一系列的pooling增加模型感受野，虽然深层的feature map具备很强的识别能力，但是随着pooling的过程导致该层feature分辨率较低，进而导致大目标的定位失准。同样的，对于小目标而言，经过一系列的增加pooling，导致其在深层的feature map上像素信息丢失，进而多数做法在浅层较大的feature map做小目标的检测。但浅层feature语义较弱，会导致识别精度的降低。因此多数的做法是将深层的feature上采样至浅层feature大小，进行特征融合，让浅层的feature具备较强的语义性。但由于目标较小，在深层feature上的上下文信息早已丢失，因此对于小目标来说，这种融合方式并不受用。  

基于上述分析，文章提出了基于dilated convolution改进的DetNet.  
## 网络结构  

具体的对比结构如下图所示：  

![image](/downloads/detnet/1.png)   

对于A,B,皆为通过downsampling实现增大感受野，C则通过对16X的map增加dilated conv实现保持较高分辨率，同时实现提升感受野。  
文章同样分析了backbone需要注意的两点：一方面是保持较高的分辨率的map容易带来较大的内存和前向时间的损耗；另一方面，减少downsampling的倍数等价于较少模型的有效感受野。为了解决这两个问题，DetNet主要做了如下改进：  
* 基于传统backbone，添加了额外的stages，如FPN中的P6被用作目标检测。这里DetNet保持feature map的分辨率不变，在stride=16x时，后续的stage同样如此。  
* 在stage 4之后为了保持feature的分辨率，文章提出了dilated conv block。  
* 对stage 5，6的通道数做了裁剪，因为高分辨率的feature map容易导致较多内存的损耗。  

具体block如下如所示：  
![image2](/downloads/detnet/2.png)   

可以看到，文章在加入dilated conv之后，并加入FPN结构增强模型性能。  

以下是一些结果图：  
![image](/downloads/detnet/3.png)     

![image](/downloads/detnet/4.png)   

## 总结  

dilated 卷积和空洞卷积的应用主要是deeplab中提出来的，主要用于保持分辨率的情况下提升模型感受野。但在目标检测任务中backbone的重新定制还是比较少见，不过感觉这是趋势，毕竟高分辨率的图对于分割、检测是相当重要的。空洞卷积这个trick还是很管用的。  

## References  

[1]: DetNet: A Backbone network for Object Detection